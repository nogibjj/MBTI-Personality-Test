{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from parrot import Parrot\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nlpaug.augmenter.word as naw\n",
    "# Download word2vec model\n",
    "os.environ[\"MODEL_DIR\"] = '/workspaces/mlops-template-Shunian-Chen/model'\n",
    "model_dir = os.environ[\"MODEL_DIR\"]\n",
    "# from nlpaug.util.file.download import DownloadUtil\n",
    "# DownloadUtil.download_word2vec(dest_dir=model_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_aug(data, num):\n",
    "    aug_text = {'text': []}\n",
    "    for text in tqdm(data):\n",
    "        paraphrases = parrot.augment(text,  max_length = 250, max_return_phrases = 5, do_diverse=False, use_gpu=True)\n",
    "        if paraphrases:\n",
    "            for para in paraphrases:\n",
    "                if para[1] != 0:\n",
    "                    aug_text['text'].append(para[0])\n",
    "                    num -= 1\n",
    "    df_aug = pd.DataFrame(aug_text)\n",
    "    return df_aug, num\n",
    "\n",
    "def data_augs(data, num, model):\n",
    "    aug_text = {'text': []}\n",
    "\n",
    "    if model == 'word_embs':\n",
    "        aug = naw.WordEmbsAug(model_type='word2vec', model_path=model_dir+'GoogleNews-vectors-negative300.bin',action=\"substitute\", device='cuda')\n",
    "    elif model == 'contextual':\n",
    "        aug = naw.ContextualWordEmbsAug(model_path='roberta-base', action=\"substitute\", device='cuda')\n",
    "    elif model == 'synonym':\n",
    "        aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "    for text in data.values.tolist():\n",
    "        augmented_text = aug.augment(str(text))\n",
    "        aug_text['text'] += augmented_text\n",
    "        num -= 1\n",
    "        if num == 0:\n",
    "            break\n",
    "    df_aug = pd.DataFrame(aug_text)\n",
    "\n",
    "    return df_aug, num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data = pd.read_csv(\"/workspaces/MBTI-Personality-Test/Data/mbti_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label   text\n",
      "0       0   7639\n",
      "1       1   6279\n",
      "2       2  55830\n",
      "3       3  40742\n",
      "4       4  12630\n",
      "5       5   9950\n",
      "6       6  69372\n",
      "7       7  48976\n",
      "8       8   3391\n",
      "9       9   1731\n",
      "10     10  25672\n",
      "11     11  26415\n",
      "12     12   1507\n",
      "13     13   1631\n",
      "14     14   7311\n",
      "15     15   8752 20489\n"
     ]
    }
   ],
   "source": [
    "cnt = origin_data.groupby(\"label\").count().reset_index()\n",
    "avg = len(origin_data) // 16\n",
    "print(cnt, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>to_aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7639</td>\n",
       "      <td>12850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6279</td>\n",
       "      <td>14210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12630</td>\n",
       "      <td>7859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>9950</td>\n",
       "      <td>10539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>69372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>48976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3391</td>\n",
       "      <td>17098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1731</td>\n",
       "      <td>18758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>25672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>26415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1507</td>\n",
       "      <td>18982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1631</td>\n",
       "      <td>18858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>7311</td>\n",
       "      <td>13178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>8752</td>\n",
       "      <td>11737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  length  to_aug\n",
       "0       0    7639   12850\n",
       "1       1    6279   14210\n",
       "2       2   55830       0\n",
       "3       3   40742       0\n",
       "4       4   12630    7859\n",
       "5       5    9950   10539\n",
       "6       6   69372       0\n",
       "7       7   48976       0\n",
       "8       8    3391   17098\n",
       "9       9    1731   18758\n",
       "10     10   25672       0\n",
       "11     11   26415       0\n",
       "12     12    1507   18982\n",
       "13     13    1631   18858\n",
       "14     14    7311   13178\n",
       "15     15    8752   11737"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug = pd.DataFrame(cnt)\n",
    "aug[\"to_aug\"] = cnt['text'].apply(lambda x: (avg - x)).clip(0)\n",
    "aug.columns = [\"label\", \"length\", \"to_aug\"]\n",
    "aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_by_label(data, num, label):\n",
    "    print(\"data: \", data.shape)\n",
    "    augmented_data, num = paraphrase_aug(data, num)\n",
    "    new_data = pd.concat([pd.DataFrame(data), augmented_data], axis=0)\n",
    "    print(\"num after paraphrase: \", num)\n",
    "    print(\"augmented_data: \", augmented_data.shape)\n",
    "    print(\"new_data: \", new_data.shape)\n",
    "    if num > 0:\n",
    "        augmented_data, num = data_augs(new_data, num, 'synonym')\n",
    "        new_data = pd.concat([new_data, augmented_data], axis=0)\n",
    "        print(\"num after synonym: \", num)\n",
    "        print(\"augmented_data: \", augmented_data.shape)\n",
    "    if num > 0:\n",
    "        augmented_data, num = data_augs(new_data, num, 'contextual')\n",
    "        new_data = pd.concat([new_data, augmented_data], axis=0)\n",
    "        print(\"num after contextual: \", num)\n",
    "        print(\"augmented_data: \", augmented_data.shape)\n",
    "    # if num > 0:\n",
    "    #     augmented_data, num = data_augs(new_data, num, label, 'word_embs')\n",
    "    #     new_data = pd.concat([new_data, augmented_data], axis=0)\n",
    "    print(\"new_data: \", new_data.shape)\n",
    "    new_data['label'] = label\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "a[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(data, aug):\n",
    "    to_aug = aug[aug['to_aug'] > 0]['label'].tolist()\n",
    "    data_augmented = data\n",
    "    for label in to_aug[4:]:\n",
    "        num = aug[aug['label'] == label]['to_aug'].values.tolist()[0]\n",
    "        print(f\"Augmenting label: {label}, num to aug: {num}\")\n",
    "\n",
    "        label_data = data[data['label'] == label].reset_index(drop=True)\n",
    "        augmented_data = augment_data_by_label(label_data['text'], num, label)\n",
    "        \n",
    "        data_augmented = pd.concat([data_augmented, augmented_data], axis=0)\n",
    "        data_augmented.to_csv(f\"mbti_train_aug{label}.csv\", index=False)\n",
    "    return data_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting label: 0, num to aug: 12850\n",
      "data:  (7639,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7639/7639 [1:52:40<00:00,  1.13it/s]  \n",
      "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/vscode/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vscode/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num after paraphrase:  8977\n",
      "augmented_data:  (3873, 1)\n",
      "new_data:  (11512, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num after synonym:  0\n",
      "augmented_data:  (8977, 1)\n",
      "new_data:  (20489, 1)\n",
      "Augmenting label: 1, num to aug: 14210\n",
      "data:  (6279,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 345/6279 [05:10<1:39:03,  1.00s/it]Bad pipe message: %s [b'*w\\xf9\\xe8\\x19\\x92\\x84\\x03QF\\x07\\xb9\\xda@\\xe9\\x03R\\xea \\x0e\\xc0\\xfc\\xdd\\x023:\"\\x99\\xfc\\xcb\\x86\\xe5nVx\\xd0\\xe7\\\\\\xedy\\xbd\\xfa~\\xd7 \\xe4\\x04\\xab7%\"\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00']\n",
      "Bad pipe message: %s [b\"\\xcb`w\\xe5;\\xfb\\xb3`\\x9e\\x9d\\xe5FUSr|Z\\xaa\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\"]\n",
      "Bad pipe message: %s [b'\\x11\\x00\\x96\\x00\\x05\\x00']\n",
      "Bad pipe message: %s [b'\\xf0', b'N\\xd7\\xff\\x85\\xa70\\xb94\\xc5o\\xcd\\x03\\xcd\\xa2o\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W', b\"\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\", b'\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08']\n",
      "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b\"\\xc0\\xb1\\x83\\x93\\xcaVP\\xe1\\x04\\x86{\\x1c'\\xd2p\\xe2\\xf8\\xe3\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\"]\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b']\\x8f)v\\xef\\xa8\\x9e0\\xcf\\xa6\\x1cS=\\xbf5+L\\xdc\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x00']\n",
      "Bad pipe message: %s [b'2\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0']\n",
      "Bad pipe message: %s [b'\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16']\n",
      "Bad pipe message: %s [b'\\xf5\\x87\\x873\\x08\\xa1\\xb6?\\x80\\xdfH\\xb9myX\\xba\\xed\\xc7\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0']\n",
      "Bad pipe message: %s [b'\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00']\n",
      "Bad pipe message: %s [b\"\\xb3\\x93\\x87\\\\*\\xea\\xbd\\xbb\\xde\\xe4m\\x89\\x11\\xcf\\xcew\\x92U\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x00\"]\n",
      "Bad pipe message: %s [b'\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01']\n",
      "Bad pipe message: %s [b'1\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00']\n",
      "Bad pipe message: %s [b\"\\xb2\\x10\\xc3%\\xcd\\xfb\\x19\\xe1\\xfbO\\x15\\xe6\\x1cmr}\\xa3n\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\"]\n",
      "Bad pipe message: %s [b'\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\\x02\\x03\\x03\\x02\\x01\\x02\\x02\\x02\\x03\\x00\\x0f\\x00\\x01\\x01']\n",
      "100%|██████████| 6279/6279 [1:32:19<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num after paraphrase:  11130\n",
      "augmented_data:  (3080, 1)\n",
      "new_data:  (9359, 1)\n",
      "num after synonym:  1771\n",
      "augmented_data:  (9359, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 373kB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:00<00:00, 49.0MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 48.7MB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:00<00:00, 23.9MB/s]\n",
      "Downloading: 100%|██████████| 501M/501M [00:06<00:00, 79.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num after contextual:  0\n",
      "augmented_data:  (1771, 1)\n",
      "new_data:  (20489, 1)\n",
      "Augmenting label: 4, num to aug: 7859\n",
      "data:  (12630,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12630/12630 [2:57:24<00:00,  1.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num after paraphrase:  1354\n",
      "augmented_data:  (6505, 1)\n",
      "new_data:  (19135, 1)\n",
      "num after synonym:  0\n",
      "augmented_data:  (1354, 1)\n",
      "new_data:  (20489, 1)\n",
      "Augmenting label: 5, num to aug: 10539\n",
      "data:  (9950,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9950/9950 [2:19:33<00:00,  1.19it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num after paraphrase:  5790\n",
      "augmented_data:  (4749, 1)\n",
      "new_data:  (14699, 1)\n",
      "num after synonym:  0\n",
      "augmented_data:  (5790, 1)\n",
      "new_data:  (20489, 1)\n",
      "Augmenting label: 8, num to aug: 17098\n",
      "data:  (3391,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 261/3391 [03:39<43:54,  1.19it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m augmented_data \u001b[39m=\u001b[39m data_augmentation(origin_data, aug)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mdata_augmentation\u001b[0;34m(data, aug)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAugmenting label: \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m, num to aug: \u001b[39m\u001b[39m{\u001b[39;00mnum\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m label_data \u001b[39m=\u001b[39m data[data[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m label]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m augmented_data \u001b[39m=\u001b[39m augment_data_by_label(label_data[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], num, label)\n\u001b[1;32m     11\u001b[0m data_augmented \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([data_augmented, augmented_data], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m data_augmented\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmbti_train_aug\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36maugment_data_by_label\u001b[0;34m(data, num, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maugment_data_by_label\u001b[39m(data, num, label):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata: \u001b[39m\u001b[39m\"\u001b[39m, data\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     augmented_data, num \u001b[39m=\u001b[39m paraphrase_aug(data, num)\n\u001b[1;32m      4\u001b[0m     new_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd\u001b[39m.\u001b[39mDataFrame(data), augmented_data], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnum after paraphrase: \u001b[39m\u001b[39m\"\u001b[39m, num)\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mparaphrase_aug\u001b[0;34m(data, num)\u001b[0m\n\u001b[1;32m      2\u001b[0m aug_text \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m: []}\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m tqdm(data):\n\u001b[0;32m----> 4\u001b[0m     paraphrases \u001b[39m=\u001b[39m parrot\u001b[39m.\u001b[39;49maugment(text,  max_length \u001b[39m=\u001b[39;49m \u001b[39m250\u001b[39;49m, max_return_phrases \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, do_diverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, use_gpu\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m paraphrases:\n\u001b[1;32m      6\u001b[0m         \u001b[39mfor\u001b[39;00m para \u001b[39min\u001b[39;00m paraphrases:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/parrot/parrot.py:112\u001b[0m, in \u001b[0;36mParrot.augment\u001b[0;34m(self, input_phrase, use_gpu, diversity_ranker, do_diverse, max_return_phrases, max_length, adequacy_threshold, fluency_threshold)\u001b[0m\n\u001b[1;32m    102\u001b[0m   preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\n\u001b[1;32m    103\u001b[0m         input_ids,\n\u001b[1;32m    104\u001b[0m         do_sample\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m         early_stopping\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m         num_return_sequences\u001b[39m=\u001b[39mmax_return_phrases)\n\u001b[1;32m    111\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m--> 112\u001b[0m   preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    113\u001b[0m           input_ids,\n\u001b[1;32m    114\u001b[0m           do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m    115\u001b[0m           max_length\u001b[39m=\u001b[39;49mmax_length, \n\u001b[1;32m    116\u001b[0m           top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, \n\u001b[1;32m    117\u001b[0m           top_p\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m, \n\u001b[1;32m    118\u001b[0m           early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    119\u001b[0m           num_return_sequences\u001b[39m=\u001b[39;49mmax_return_phrases) \n\u001b[1;32m    122\u001b[0m paraphrases\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m pred \u001b[39min\u001b[39;00m preds:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1571\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1564\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1565\u001b[0m         expand_size\u001b[39m=\u001b[39mnum_return_sequences,\n\u001b[1;32m   1566\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1567\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1568\u001b[0m     )\n\u001b[1;32m   1570\u001b[0m     \u001b[39m# 12. run sample\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m   1572\u001b[0m         input_ids,\n\u001b[1;32m   1573\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1574\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[1;32m   1575\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1576\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1577\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1578\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1579\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1580\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1581\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1582\u001b[0m     )\n\u001b[1;32m   1584\u001b[0m \u001b[39melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1585\u001b[0m     \u001b[39mif\u001b[39;00m num_return_sequences \u001b[39m>\u001b[39m num_beams:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:2534\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2533\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2534\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2535\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2536\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2537\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2538\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2539\u001b[0m )\n\u001b[1;32m   2541\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2542\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1648\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   1647\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1649\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1650\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1651\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1652\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1653\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   1654\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1655\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1656\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1657\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1658\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1659\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1660\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1661\u001b[0m )\n\u001b[1;32m   1663\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1665\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[1;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1052\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:673\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    674\u001b[0m     hidden_states,\n\u001b[1;32m    675\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    676\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    677\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    678\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    679\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    680\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    681\u001b[0m )\n\u001b[1;32m    682\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    683\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:578\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    569\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    570\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m ):\n\u001b[0;32m--> 578\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_norm(hidden_states)\n\u001b[1;32m    579\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSelfAttention(\n\u001b[1;32m    580\u001b[0m         normed_hidden_states,\n\u001b[1;32m    581\u001b[0m         mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m         output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:256\u001b[0m, in \u001b[0;36mT5LayerNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[39m# T5 uses a layer_norm which only scales and doesn't shift, which is also known as Root Mean\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39m# Square Layer Normalization https://arxiv.org/abs/1910.07467 thus varience is calculated\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[39m# w/o mean and there is no bias. Additionally we want to make sure that the accumulation for\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[39m# half-precision inputs is done in fp32\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     variance \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 256\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39;49mrsqrt(variance \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariance_epsilon)\n\u001b[1;32m    258\u001b[0m     \u001b[39m# convert into half-precision if necessary\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m [torch\u001b[39m.\u001b[39mfloat16, torch\u001b[39m.\u001b[39mbfloat16]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "augmented_data = data_augmentation(origin_data, aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data.to_csv(\"mbti_train_augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327828, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388749, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac6dcd399ab8cd2ecc0f6e8f154efd75b4aa37c8093b73598011b1aae01f02fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
